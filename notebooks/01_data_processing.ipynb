{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICPSR Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and Exporting Hate Crime Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dictionary mapping each year to its corresponding TSV file path\n",
    "year_paths = {\n",
    "    2023: '../data/ICPSR_2023/DS0003/39270-0003-Data.tsv',\n",
    "    2022: '../data/ICPSR_2022/DS0003/38925-0003-Data.tsv',\n",
    "    2021: '../data/ICPSR_2021/DS0003/38807-0003-Data.tsv',\n",
    "    2020: '../data/ICPSR_2020/DS0003/38566-0003-Data.tsv',\n",
    "    2019: '../data/ICPSR_2019/DS0003/38565-0003-Data.tsv',\n",
    "    2018: '../data/ICPSR_2018/DS0003/37649-0003-Data.tsv',\n",
    "    2017: '../data/ICPSR_2017/DS0003/37650-0003-Data.tsv',\n",
    "    2016: '../data/ICPSR_2016/DS0003/37066-0003-Data.tsv',\n",
    "    2015: '../data/ICPSR_2015/DS0003/36851-0003-Data.tsv',\n",
    "}\n",
    "\n",
    "# Set the chunk size for reading large TSV files\n",
    "chunk_size = 500_000\n",
    "\n",
    "# Loop through each year and process the corresponding file\n",
    "for year, tsv_file in year_paths.items():\n",
    "    print(f\"Processing {year}...\")\n",
    "    filtered_chunks = []\n",
    "\n",
    "    # Read TSV file in chunks to avoid memory overload\n",
    "    for chunk in pd.read_csv(tsv_file, sep='\\t', chunksize=chunk_size, dtype={'V20201': str}):\n",
    "        # Filter rows where bias motivation code is not \"88\" (i.e., not 'None')\n",
    "        filtered_chunk = chunk[chunk['V20201'] != '88']\n",
    "        filtered_chunks.append(filtered_chunk)\n",
    "\n",
    "    # Combine all filtered chunks into a single DataFrame\n",
    "    df_filtered = pd.concat(filtered_chunks, ignore_index=True)\n",
    "\n",
    "    # Save the filtered data to a CSV file named by year\n",
    "    df_filtered.to_csv(f'{year}-03.csv', index=False)\n",
    "    print(f\"{year} data saved to {year}-03.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files from 2023 to 2015 into a list of DataFrames\n",
    "df_list = [pd.read_csv(f'{year}-03.csv') for year in range(2023, 2014, -1)]\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Check the combined DataFrame\n",
    "print(combined_df.head())\n",
    "print(combined_df.shape)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv('2015-2023_03.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
