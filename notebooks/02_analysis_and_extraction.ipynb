{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FBI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/hate_crime_fbi.csv')\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering by keywords\n",
    "black_df = df[df['bias_desc'].str.contains('Anti-Black', case=False, na=False)].copy()\n",
    "hispanic_df = df[df['bias_desc'].str.contains('Anti-Hispanic', case=False, na=False)].copy()\n",
    "asian_df = df[df['bias_desc'].str.contains('Anti-Asian', case=False, na=False)].copy()\n",
    "\n",
    "# Assigning labels to each category\n",
    "black_df['group'] = 'Anti-Black'\n",
    "hispanic_df['group'] = 'Anti-Hispanic'\n",
    "asian_df['group'] = 'Anti-Asian'\n",
    "\n",
    "# Combining the filtered DataFrames\n",
    "combined_df = pd.concat([black_df, hispanic_df, asian_df])\n",
    "\n",
    "# Aggregating the number of incidents per year\n",
    "counts_by_year = (\n",
    "    combined_df.groupby(['data_year', 'group'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "counts_by_year.to_csv(\"counts_by_year.csv\", index=False)\n",
    "\n",
    "chart = alt.Chart(counts_by_year).mark_line(point=True).encode(\n",
    "    x=alt.X('data_year:O', title='Year'),\n",
    "    y=alt.Y('count:Q', title='Number of Incidents'),\n",
    "    color=alt.Color('group:N', title='Bias Type')\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400,\n",
    "    title='Hate Crime Incidents by Bias Type and Year'\n",
    ")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by keywords\n",
    "black_df = df[df['bias_desc'].str.contains('Anti-Black', case=False, na=False)].copy()\n",
    "hispanic_df = df[df['bias_desc'].str.contains('Anti-Hispanic', case=False, na=False)].copy()\n",
    "asian_df = df[df['bias_desc'].str.contains('Anti-Asian', case=False, na=False)].copy()\n",
    "\n",
    "# Assign labels to each category\n",
    "black_df['group'] = 'Anti-Black'\n",
    "hispanic_df['group'] = 'Anti-Hispanic'\n",
    "asian_df['group'] = 'Anti-Asian'\n",
    "\n",
    "# Combine the filtered DataFrames\n",
    "combined_df = pd.concat([black_df, hispanic_df, asian_df])\n",
    "\n",
    "# Aggregate the number of incidents per year\n",
    "counts_by_year = (\n",
    "    combined_df.groupby(['data_year', 'group'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "# Population by race/ethnicity (based on 2020 Census, fixed)\n",
    "population_dict = {\n",
    "    'Anti-Black': 41288572,\n",
    "    'Anti-Hispanic': 61755866,\n",
    "    'Anti-Asian': 19112979\n",
    "}\n",
    "\n",
    "# Map population and calculate incidents per 100,000 people\n",
    "counts_by_year['population'] = counts_by_year['group'].map(population_dict)\n",
    "counts_by_year['per_100k'] = counts_by_year['count'] / counts_by_year['population'] * 100000\n",
    "\n",
    "# Draw the chart with Altair (per capita basis)\n",
    "chart = alt.Chart(counts_by_year).mark_line(point=True).encode(\n",
    "    x=alt.X('data_year:O', title='Year'),\n",
    "    y=alt.Y('per_100k:Q', title='Incidents per 100,000 People'),\n",
    "    color=alt.Color('group:N', title='Bias Type'),\n",
    "    tooltip=['data_year', 'group', 'per_100k']\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400,\n",
    "    title='Hate Crime Incidents per 100,000 People by Bias Type and Year'\n",
    ")\n",
    "\n",
    "counts_by_year.to_csv(\"counts_per_100k.csv\", index=False)\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to compare\n",
    "columns_to_compare = ['victim_types', 'location_name', 'offender_race']\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Filter by each bias group\n",
    "groups = {\n",
    "    'Anti-Black': df[df['bias_desc'].str.contains('Anti-Black', case=False, na=False)].copy(),\n",
    "    'Anti-Hispanic': df[df['bias_desc'].str.contains('Anti-Hispanic', case=False, na=False)].copy(),\n",
    "    'Anti-Asian': df[df['bias_desc'].str.contains('Anti-Asian', case=False, na=False)].copy()\n",
    "}\n",
    "\n",
    "# Aggregate for each column\n",
    "for col in columns_to_compare:\n",
    "    frames = []\n",
    "    for group_name, group_df in groups.items():\n",
    "        # Calculate percentages\n",
    "        count = group_df[col].value_counts(dropna=False, normalize=True) * 100\n",
    "        count_df = count.rename(f'{group_name} (%)').reset_index()\n",
    "        count_df.columns = [col, f'{group_name} (%)']\n",
    "        frames.append(count_df.set_index(col))\n",
    "    \n",
    "    # Join horizontally\n",
    "    comparison_df = pd.concat(frames, axis=1).fillna(0).reset_index()\n",
    "    results[col] = comparison_df\n",
    "\n",
    "# Display results by category (uncomment as needed)\n",
    "\n",
    "print(\"=== Comparison by victim_types ===\")\n",
    "print(results['victim_types'].to_string(index=False))\n",
    "print(\"\\n=== Comparison by location_name ===\")\n",
    "print(results['location_name'].to_string(index=False))\n",
    "print(\"\\n=== Comparison by offender_race ===\")\n",
    "print(results['offender_race'].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2015-2023_03.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anti-Black=12, Anti-Asian=14, Anti-Hispanic=32\n",
    "target_codes = [12, 14, 32]\n",
    "\n",
    "race_df = df[df['V20201'].isin(target_codes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Target bias motivation codes and their labels\n",
    "target_codes = {\n",
    "    12: 'Anti-Black',\n",
    "    14: 'Anti-Asian',\n",
    "    32: 'Anti-Hispanic'\n",
    "}\n",
    "\n",
    "# Define a parser that can handle multiple date formats\n",
    "def parse_date(date_str):\n",
    "    for fmt in ('%Y%m%d', '%d-%b-%Y', '%Y-%m-%d'):\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=fmt)\n",
    "        except (ValueError, TypeError):\n",
    "            continue\n",
    "    return pd.NaT\n",
    "\n",
    "# Clean INCDATE in the entire race_df\n",
    "race_df['INCDATE'] = race_df['INCDATE'].apply(parse_date)\n",
    "\n",
    "# Remove rows with unparseable dates\n",
    "race_df = race_df.dropna(subset=['INCDATE'])\n",
    "\n",
    "# Extract year from the cleaned date\n",
    "race_df['YEAR'] = race_df['INCDATE'].dt.year\n",
    "\n",
    "# Filter rows where V20201 matches any of the target codes\n",
    "race_df_filtered = race_df[race_df['V20201'].isin(target_codes.keys())].copy()\n",
    "\n",
    "# Map bias code to label\n",
    "race_df_filtered['label'] = race_df_filtered['V20201'].map(target_codes)\n",
    "\n",
    "# Aggregate number of incidents by year and bias label\n",
    "yearly_counts = (\n",
    "    race_df_filtered\n",
    "    .groupby(['YEAR', 'label'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "# Create Altair line chart\n",
    "chart = alt.Chart(yearly_counts).mark_line(point=True).encode(\n",
    "    x=alt.X('YEAR:O', title='Year'),\n",
    "    y=alt.Y('count:Q', title='Number of Incidents'),\n",
    "    color=alt.Color('label:N', title='Bias Motivation'),\n",
    "    tooltip=['YEAR', 'label', 'count']\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400,\n",
    "    title='Hate Crime Incidents by Year and Bias Motivation (V20201 only)'\n",
    ")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Ensure INCDATE is already parsed to datetime in race_df\n",
    "race_df['MONTH'] = race_df['INCDATE'].dt.month\n",
    "\n",
    "# Target bias motivation codes and their labels\n",
    "target_codes = {\n",
    "    12: 'Anti-Black',\n",
    "    14: 'Anti-Asian',\n",
    "    32: 'Anti-Hispanic'\n",
    "}\n",
    "\n",
    "# Filter for selected bias motivations\n",
    "race_df_filtered = race_df[race_df['V20201'].isin(target_codes.keys())].copy()\n",
    "race_df_filtered['label'] = race_df_filtered['V20201'].map(target_codes)\n",
    "\n",
    "# Count incidents by month and label\n",
    "monthly_counts = (\n",
    "    race_df_filtered\n",
    "    .groupby(['label', 'MONTH'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "# Calculate percentage by group (label)\n",
    "monthly_counts['percentage'] = (\n",
    "    monthly_counts\n",
    "    .groupby('label')['count']\n",
    "    .transform(lambda x: x / x.sum() * 100)\n",
    ")\n",
    "\n",
    "# Make sure month is categorical for correct ordering\n",
    "monthly_counts['MONTH'] = monthly_counts['MONTH'].astype(int).astype(str)\n",
    "\n",
    "# Altair chart: percentage of incidents by month\n",
    "chart = alt.Chart(monthly_counts).mark_line(point=True).encode(\n",
    "    x=alt.X('MONTH:O', title='Month'),\n",
    "    y=alt.Y('percentage:Q', title='Share of Incidents (%)'),\n",
    "    color=alt.Color('label:N', title='Bias Motivation'),\n",
    "    tooltip=['label', 'MONTH', 'percentage']\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400,\n",
    "    title='Monthly Distribution of Hate Crimes by Bias Motivation (as % of Total)'\n",
    ")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCR OFFENSE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation (frequency)\n",
    "offense_bias_table = pd.crosstab(race_df['V20201'], race_df['V20061'])\n",
    "\n",
    "# Display the result\n",
    "print(offense_bias_table)\n",
    "\n",
    "# Cross-tabulation (percentage per V20201)\n",
    "offense_bias_pct = pd.crosstab(race_df['V20201'], race_df['V20061'], normalize='index') * 100\n",
    "\n",
    "# Display rounded to two decimal places\n",
    "print(offense_bias_pct.round(2))\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "# Convert data to long format\n",
    "offense_bias_df = offense_bias_pct.reset_index().melt(\n",
    "    id_vars='V20201', \n",
    "    var_name='V20061', \n",
    "    value_name='percentage'\n",
    ")\n",
    "\n",
    "# Draw a heatmap with Altair\n",
    "heatmap = alt.Chart(offense_bias_df).mark_rect().encode(\n",
    "    x=alt.X('V20061:N', title='UCR Offense Code (V20061)'),\n",
    "    y=alt.Y('V20201:N', title='Bias Motivation (V20201)'),\n",
    "    color=alt.Color('percentage:Q', title='Percentage (%)', scale=alt.Scale(scheme='blues')),\n",
    "    tooltip=['V20201', 'V20061', 'percentage']\n",
    ").properties(\n",
    "    title='Bias Motivation by UCR Offense Code',\n",
    "    width=600,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELATIONSHIP VIC TO OFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation (showing percentages)\n",
    "cross_table_pct = pd.crosstab(race_df['V20201'], race_df['V40321'], normalize='index') * 100\n",
    "\n",
    "# Round to two decimal places\n",
    "print(cross_table_pct.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df['V40321_filled'] = race_df['V40321'].astype(str).replace({'nan': 'Unknown'})\n",
    "\n",
    "cross_table_pct = pd.crosstab(race_df['V20201'], race_df['V40321_filled'], normalize='index') * 100\n",
    "\n",
    "print(cross_table_pct.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map V20201 bias motivation to target group labels\n",
    "bias_mapping = {\n",
    "    12: 'Anti-Black',\n",
    "    14: 'Anti-Asian',\n",
    "    32: 'Anti-Hispanic'\n",
    "}\n",
    "race_df['bias_group'] = race_df['V20201'].map(bias_mapping)\n",
    "\n",
    "# Function to map victim-offender relationship to 3 categories\n",
    "def classify_relationship(val):\n",
    "    try:\n",
    "        val = int(val)\n",
    "        if val == 25:\n",
    "            return 'Stranger'\n",
    "        elif val in list(range(1, 25+1)) + [26]:\n",
    "            return 'Acquaintance'\n",
    "        elif val == 27:\n",
    "            return 'Unknown'\n",
    "        else:\n",
    "            return 'Unknown'\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Apply the relationship classification\n",
    "race_df['relationship_category'] = race_df['V40321'].apply(classify_relationship)\n",
    "\n",
    "# Crosstab by bias group and relationship category, showing row-wise percentages\n",
    "cross_table = pd.crosstab(race_df['bias_group'], race_df['relationship_category'], normalize='index') * 100\n",
    "\n",
    "# Print rounded table\n",
    "print(cross_table.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Crosstab with original V40321 values (normalized to row percentages)\n",
    "raw_pct = pd.crosstab(race_df['V20201'], race_df['V40321'], normalize='index') * 100\n",
    "\n",
    "# Step 2: Define grouping of original V40321 codes\n",
    "group_map = {\n",
    "    'Stranger': [25],\n",
    "    'Unknown': [0, 27, -9, -8, -7, -6, -5],\n",
    "    'Acquaintance': []  # we will fill this below\n",
    "}\n",
    "\n",
    "# Step 3: Get actual codes that exist in the data\n",
    "actual_codes = set(raw_pct.columns)\n",
    "\n",
    "# Step 4: Automatically assign all remaining codes to 'Acquaintance'\n",
    "used_codes = set(group_map['Stranger'] + group_map['Unknown'])\n",
    "group_map['Acquaintance'] = list(actual_codes - used_codes)\n",
    "\n",
    "# Step 5: Aggregate using original row-normalized percentages\n",
    "simplified_pct = pd.DataFrame(index=raw_pct.index)\n",
    "\n",
    "for group, codes in group_map.items():\n",
    "    # Only sum columns that actually exist in raw_pct\n",
    "    valid_codes = [code for code in codes if code in raw_pct.columns]\n",
    "    if valid_codes:\n",
    "        simplified_pct[group] = raw_pct[valid_codes].sum(axis=1)\n",
    "    else:\n",
    "        simplified_pct[group] = 0  # If no valid codes, fill with 0s\n",
    "\n",
    "# Step 6: Rename race codes to readable labels\n",
    "race_labels = {12: 'Anti-Asian', 14: 'Anti-Black', 32: 'Anti-Hispanic'}\n",
    "simplified_pct.index = simplified_pct.index.map(race_labels)\n",
    "\n",
    "# Step 7: Display\n",
    "print(simplified_pct.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Map V20201 to bias group labels\n",
    "bias_mapping = {\n",
    "    12: 'Anti-Black',\n",
    "    14: 'Anti-Asian',\n",
    "    32: 'Anti-Hispanic'\n",
    "}\n",
    "race_df['bias_group'] = race_df['V20201'].map(bias_mapping)\n",
    "\n",
    "# Step 2: Map V40321 to relationship category\n",
    "def classify_relationship(val):\n",
    "    try:\n",
    "        val = int(val)\n",
    "        if val == 25:\n",
    "            return 'Stranger'\n",
    "        elif val in list(range(1, 26)) + [26]:\n",
    "            return 'Acquaintance'\n",
    "        elif val == 27:\n",
    "            return 'Unknown'\n",
    "        else:\n",
    "            return 'Unknown'\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "\n",
    "race_df['relationship_category'] = race_df['V40321'].apply(classify_relationship)\n",
    "\n",
    "# Step 3: Crosstab with row-wise normalization (percentages)\n",
    "cross_table = pd.crosstab(race_df['bias_group'], race_df['relationship_category'], normalize='index') * 100\n",
    "\n",
    "# Step 4: Save to CSV for D3 use\n",
    "cross_table_csv = cross_table.reset_index()\n",
    "cross_table_csv.to_csv(\"relationship_distribution.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Victim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation (showing percentages)\n",
    "cross_table_pct = pd.crosstab(race_df['V20201'], race_df['V40221'], normalize='index') * 100\n",
    "\n",
    "# Round to two decimal places\n",
    "print(cross_table_pct.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Victim Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df['V40191'] = pd.to_numeric(race_df['V40191'], errors='coerce')\n",
    "\n",
    "cross_table_pct = pd.crosstab(race_df['V20201'], race_df['V40191'], normalize='index') * 100\n",
    "\n",
    "print(cross_table_pct.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Victim Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation (showing percentages)\n",
    "cross_table_pct = pd.crosstab(race_df['V20201'], race_df['V40201'], normalize='index') * 100\n",
    "\n",
    "# Round to two decimal places\n",
    "print(cross_table_pct.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Victim Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "race_df['V40181'] = pd.to_numeric(race_df['V40181'], errors='coerce')\n",
    "\n",
    "race_df_clean = race_df.dropna(subset=['V40181'])\n",
    "\n",
    "race_df_clean['age_group'] = pd.cut(\n",
    "    race_df_clean['V40181'],\n",
    "    bins=range(0, 101, 10),\n",
    "    right=False,\n",
    "    labels=['0–9', '10–19', '20–29', '30–39', '40–49',\n",
    "            '50–59', '60–69', '70–79', '80–89', '90–99']\n",
    ")\n",
    "\n",
    "cross_table_pct = pd.crosstab(\n",
    "    race_df_clean['V20201'],\n",
    "    race_df_clean['age_group'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "race_labels = {\n",
    "    12: 'Anti-Black',\n",
    "    14: 'Anti-Asian',\n",
    "    32: 'Anti-Hispanic'\n",
    "}\n",
    "cross_table_pct.index = cross_table_pct.index.map(race_labels)\n",
    "\n",
    "\n",
    "print(cross_table_pct.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "race_df['V40181'] = pd.to_numeric(race_df['V40181'], errors='coerce')\n",
    "df = race_df.dropna(subset=['V40181'])\n",
    "race_labels = {12: 'Anti-Black', 14: 'Anti-Asian', 32: 'Anti-Hispanic'}\n",
    "df = df[df['V20201'].isin(race_labels)].copy()\n",
    "df['race_label'] = df['V20201'].map(race_labels)\n",
    "\n",
    "output = []\n",
    "\n",
    "x_grid = np.linspace(0, 100, 200)\n",
    "\n",
    "for label in df['race_label'].unique():\n",
    "    values = df[df['race_label'] == label]['V40181'].dropna()\n",
    "    kde = gaussian_kde(values)\n",
    "    densities = kde(x_grid)\n",
    "    for x, y in zip(x_grid, densities):\n",
    "        output.append({'race_label': label, 'age': x, 'density': y})\n",
    "\n",
    "output_df = pd.DataFrame(output)\n",
    "output_df.to_csv('age_density_by_race.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "chart = alt.Chart(df).transform_density(\n",
    "    'V40181',\n",
    "    as_=['age', 'density'],\n",
    "    groupby=['race_label']\n",
    ").mark_line(opacity=0.7, strokeWidth=2).encode(\n",
    "    x=alt.X('age:Q', title='Age'),\n",
    "    y=alt.Y('density:Q', title='Density'),\n",
    "    color=alt.Color('race_label:N', title='Bias Motivation')\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=300,\n",
    "    title='Age Density Comparison by Bias Motivation'\n",
    ")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# Convert age to numeric\n",
    "race_df['V40181'] = pd.to_numeric(race_df['V40181'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing age and filter for target racial bias groups\n",
    "df = race_df.dropna(subset=['V40181'])\n",
    "race_labels = {12: 'Anti-Black', 14: 'Anti-Asian', 32: 'Anti-Hispanic'}\n",
    "df = df[df['V20201'].isin(race_labels.keys())].copy()\n",
    "df['race_label'] = df['V20201'].map(race_labels)\n",
    "\n",
    "# Restrict age range to 0–99 and convert to integer\n",
    "df = df[(df['V40181'] >= 0) & (df['V40181'] < 100)]\n",
    "df['age'] = df['V40181'].astype(int)\n",
    "\n",
    "# Create a cross table of counts per race and age\n",
    "counts = (\n",
    "    df.groupby(['race_label', 'age'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "# Convert to percentage within each race group\n",
    "counts['percentage'] = (\n",
    "    counts.groupby('race_label')['count']\n",
    "    .transform(lambda x: x / x.sum() * 100)\n",
    ")\n",
    "\n",
    "# Draw Altair heatmap\n",
    "heatmap = alt.Chart(counts).mark_rect().encode(\n",
    "    x=alt.X('age:O', title='Age'),\n",
    "    y=alt.Y('race_label:N', title='Bias Motivation'),\n",
    "    color=alt.Color('percentage:Q', title='Share (%)', scale=alt.Scale(scheme='reds')),\n",
    "    tooltip=['race_label', 'age', 'percentage']\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=150,\n",
    "    title='Age Distribution of Victims by Bias Motivation (Heatmap)'\n",
    ")\n",
    "\n",
    "heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sex x Age of Victim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "bias_map = {12: \"Anti-Black\", 14: \"Anti-Asian\", 32: \"Anti-Hispanic\"}\n",
    "sex_map = {0: \"Female\", 1: \"Male\"}\n",
    "\n",
    "df = race_df[\n",
    "    race_df[\"V20201\"].isin(bias_map.keys()) &\n",
    "    race_df[\"V40191\"].isin(sex_map.keys())\n",
    "].copy()\n",
    "\n",
    "df[\"bias_group\"] = df[\"V20201\"].map(bias_map)\n",
    "df[\"sex\"] = df[\"V40191\"].map(sex_map)\n",
    "df[\"age\"] = pd.to_numeric(df[\"V40181\"], errors=\"coerce\")\n",
    "df[\"age_range\"] = pd.cut(df[\"age\"], bins=range(0, 100, 5), right=False).astype(str)\n",
    "age_range_order = sorted(df[\"age_range\"].unique().tolist())\n",
    "\n",
    "grouped = (\n",
    "    df.groupby([\"bias_group\", \"sex\", \"age_range\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "grouped[\"percent\"] = grouped.groupby(\"bias_group\")[\"count\"].transform(lambda x: x / x.sum() * 100)\n",
    "\n",
    "\n",
    "chart = alt.Chart(grouped).mark_rect().encode(\n",
    "    x=alt.X(\"age_range:N\", title=\"Age Range\", sort=age_range_order),\n",
    "    y=alt.Y(\"sex:N\", title=\"Sex\"),\n",
    "    color=alt.Color(\"percent:Q\", title=\"Percentage\", scale=alt.Scale(scheme=\"blues\"))\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=80\n",
    ")\n",
    "\n",
    "final_chart = chart.facet(\n",
    "    row=alt.Row(\"bias_group:N\", title=None, sort=[\"Anti-Asian\", \"Anti-Black\", \"Anti-Hispanic\"])\n",
    ").properties(\n",
    "    title=\"Age and Sex Distribution by Bias Motivation (Percentage)\"\n",
    ")\n",
    "\n",
    "final_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation (showing percentages)\n",
    "cross_table_pct = pd.crosstab(race_df['V20201'], race_df['V20111'], normalize='index') * 100\n",
    "\n",
    "# Round to two decimal places\n",
    "print(cross_table_pct.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for location category classification\n",
    "location_map = {\n",
    "    20: 'Residence', 54: 'Residence',\n",
    "    3: 'Commercial', 7: 'Commercial', 8: 'Commercial',\n",
    "    12: 'Commercial', 14: 'Commercial', 17: 'Commercial',\n",
    "    21: 'Commercial', 23: 'Commercial', 24: 'Commercial',\n",
    "    55: 'Commercial',\n",
    "    1: 'Road', 13: 'Road', 18: 'Road',\n",
    "    39: 'Road', 40: 'Road', 51: 'Road',\n",
    "    4: 'School', 11: 'School', 22: 'School',\n",
    "    50: 'School', 53: 'School', 57: 'School',\n",
    "    5: 'Other', 6: 'Other', 15: 'Other', 25: 'Other',\n",
    "    37: 'Other', 41: 'Other', 45: 'Other', 46: 'Other',\n",
    "    47: 'Other', 48: 'Other', 49: 'Other', 56: 'Other',\n",
    "    58: 'Other'\n",
    "}\n",
    "\n",
    "# Apply location categories to V20111\n",
    "race_df.loc[:, 'LocationCategory'] = race_df['V20111'].map(location_map).fillna('Other')\n",
    "\n",
    "# Mapping from numeric race codes to human-readable labels\n",
    "race_labels = {\n",
    "    12: 'Anti-Black',\n",
    "    14: 'Anti-Asian',\n",
    "    32: 'Anti-Hispanic'\n",
    "}\n",
    "\n",
    "# Cross-tabulation: row-wise percentage of incidents by location category\n",
    "cross_table_pct_grouped = pd.crosstab(\n",
    "    race_df['V20201'], race_df['LocationCategory'], normalize='index'\n",
    ") * 100\n",
    "\n",
    "# Rename index using race labels\n",
    "cross_table_pct_grouped.index = cross_table_pct_grouped.index.map(race_labels)\n",
    "\n",
    "# Add index name for correct CSV column label\n",
    "cross_table_pct_grouped.index.name = 'Race'\n",
    "\n",
    "# Reorder columns\n",
    "columns_order = ['Residence', 'School', 'Commercial', 'Road', 'Other']\n",
    "cross_table_pct_grouped = cross_table_pct_grouped[columns_order]\n",
    "\n",
    "# Display table\n",
    "print(cross_table_pct_grouped.round(2))\n",
    "\n",
    "# Save to CSV\n",
    "cross_table_pct_grouped.round(2).to_csv(\"location_distribution.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offender Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation (showing percentages)\n",
    "cross_table_pct = pd.crosstab(race_df['V20201'], race_df['V50081'], normalize='index') * 100\n",
    "\n",
    "# Round to two decimal places\n",
    "print(cross_table_pct.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offender Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation (showing percentages)\n",
    "cross_table_pct = pd.crosstab(race_df['V20201'], race_df['V50091'], normalize='index') * 100\n",
    "\n",
    "# Round to two decimal places\n",
    "print(cross_table_pct.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offender Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation (showing percentages)\n",
    "cross_table_pct = pd.crosstab(race_df['V20201'], race_df['V50111'], normalize='index') * 100\n",
    "\n",
    "# Round to two decimal places\n",
    "print(cross_table_pct.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation (showing percentages)\n",
    "cross_table_pct = pd.crosstab(race_df['V50111'], race_df['V50091'], normalize='index') * 100\n",
    "\n",
    "# Round to two decimal places\n",
    "print(cross_table_pct.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offence Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offense code → offense category mapping（例）\n",
    "def categorize_offense(code):\n",
    "    if pd.isna(code):\n",
    "        return 'Missing'\n",
    "    try:\n",
    "        code = int(code)\n",
    "    except:\n",
    "        return 'Invalid'\n",
    "    \n",
    "    if 90 <= code < 100:\n",
    "        return 'Homicide'\n",
    "    elif 100 <= code < 130:\n",
    "        return 'Sex Offense / Robbery'\n",
    "    elif 130 <= code < 200:\n",
    "        return 'Assault / Intimidation'\n",
    "    elif 200 <= code < 240:\n",
    "        return 'Property Crime'\n",
    "    elif 240 <= code < 270:\n",
    "        return 'Fraud / Theft'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# 新しいカテゴリ列を追加\n",
    "race_df['Offense_Category'] = race_df['V20061'].apply(categorize_offense)\n",
    "\n",
    "# クロス集計（行: V20201、列: offense category）\n",
    "cross_table_pct = pd.crosstab(\n",
    "    race_df['V20201'], \n",
    "    race_df['Offense_Category'], \n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "# 小数点2桁で表示\n",
    "print(cross_table_pct.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# クロス集計（既に集計済みと仮定）\n",
    "cross_table_pct = pd.crosstab(\n",
    "    race_df['V20201'],\n",
    "    race_df['Offense_Category'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "# 描画\n",
    "ax = cross_table_pct.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "plt.title('Offense Category Distribution by Victim Race')\n",
    "plt.xlabel('Victim Race (V20201)')\n",
    "plt.ylabel('Percentage')\n",
    "plt.legend(title='Offense Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offender Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert non-numeric values (e.g., strings) to NaN and then to numeric\n",
    "race_df['V50071'] = pd.to_numeric(race_df['V50071'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN in the age column (exclude missing age data from analysis)\n",
    "race_df_clean = race_df.dropna(subset=['V50071'])\n",
    "\n",
    "# Group age into 10-year bins\n",
    "race_df_clean['age_group'] = pd.cut(\n",
    "    race_df_clean['V50071'],\n",
    "    bins=range(0, 101, 10),\n",
    "    right=False,\n",
    "    labels=['0-9','10-19','20-29','30-39','40-49',\n",
    "            '50-59','60-69','70-79','80-89','90-99']\n",
    ")\n",
    "\n",
    "# Group by age_group and V20201, then reshape into long format\n",
    "age_group_counts = (\n",
    "    race_df_clean.groupby(['V20201', 'age_group'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "# Calculate the percentage within each Bias Motivation group\n",
    "age_group_counts['percentage'] = (\n",
    "    age_group_counts.groupby('V20201')['count']\n",
    "    .transform(lambda x: x / x.sum() * 100)\n",
    ")\n",
    "\n",
    "# Plot with Altair\n",
    "import altair as alt\n",
    "\n",
    "chart = alt.Chart(age_group_counts).mark_bar().encode(\n",
    "    x=alt.X('age_group:N', title='Age Group'),\n",
    "    y=alt.Y('percentage:Q', title='Percentage (%)'),\n",
    "    color=alt.Color('age_group:N', legend=None),\n",
    "    column=alt.Column('V20201:N', title='Bias Motivation (V20201)')\n",
    ").properties(\n",
    "    width=100,\n",
    "    height=300,\n",
    "    title='Age Distribution by Bias Motivation'\n",
    ")\n",
    "\n",
    "chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
